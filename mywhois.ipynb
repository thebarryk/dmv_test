{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class to accumulate whois records and risk factors.\n",
    "They will memoized to reduce requested services for more data.\n",
    "\n",
    "1. Use a database to store the results for use in various programs.\n",
    "2. Use an ipnetwork as key\n",
    "3. Store company name with key\n",
    "4. When a class instance is created, it will load db into dictionary.\n",
    "5. The instance is normally readonly, but can be writeable. That means new addresses\n",
    "will be added if they are not in the database and become permanent parts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=9 new=0 old=10 risk.len()=0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipaddress\n",
    "import dbm\n",
    "import pickle\n",
    "from sortedcontainers import SortedDict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import os\n",
    "import traceback\n",
    "import datetime\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "class Debug():\n",
    "    \"\"\" Print debug messages if active \"\"\"\n",
    "    def __init__(self, set=1):\n",
    "        self._set = set\n",
    "    def prt(self, str):\n",
    "        if self._set:\n",
    "            sys.stderr.write(str)\n",
    "    def set(self):\n",
    "        self._set = 1\n",
    "    def unset(self):\n",
    "        self._set = 0\n",
    "debug = Debug()\n",
    "\n",
    "\n",
    "def get_risk(ip_string):\n",
    "    # Return risk factors from scamalytics into a dict\n",
    "    #     {\"ip\": ? , \n",
    "    #      \"score\": ?, \n",
    "    #      \"risk\": ?, \n",
    "    #      \"risk_comment: ?\"}\n",
    "\n",
    "    # Fetch the complete record from scamalytics restful api\n",
    "    # ip_string ... make request by ip address as a string\n",
    "\n",
    "    html_text = \"\"\n",
    "    url = \"https://scamalytics.com/ip/\" + ip_string\n",
    "    html_text = requests.get(url).text\n",
    "\n",
    "#     soup = BeautifulSoup(html_text, 'lxml')\n",
    "    soup = BeautifulSoup(html_text, 'xml')\n",
    "    \n",
    "    # Tag=pre\n",
    "    result = json.loads(soup.pre.string)\n",
    "    \n",
    "    # The comment is in the body of an unlabelled div. Used the css class to find.\n",
    "    # Remove special UTF-8 character \\U200b, a zero width space.\n",
    "#     result[\"risk_comment\"] = soup.find_all(\"div\", class_=\"panel_body\")[0].get_text().replace(\"\\u200b\",\"\")\n",
    "    result[\"risk_comment\"] = \"\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_arin(html_text, ip_string):\n",
    "    # Values that are not found are set to np.NaN\n",
    "    \n",
    "    fillna = lambda x: np.nan if x is None else x if isinstance(x, str) else x.string\n",
    "    \n",
    "    def get_streetaddress(soup):\n",
    "        # More than one address line may be recorded\n",
    "        tag = soup.org.streetaddress\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        address = []\n",
    "        for line in tag:\n",
    "            address.append(line.string)\n",
    "        return address\n",
    "    def get_postalcode(soup):\n",
    "        return fillna(soup.org.postalcode)\n",
    "    def get_city(soup):\n",
    "        return fillna(soup.org.city)\n",
    "    def get_handle(soup):\n",
    "        return fillna(soup.org.handle)\n",
    "    def get_state(soup):\n",
    "        # The iso3166 tags are the international country codes\n",
    "        # Ref: https://www.iso.org/glossary-for-iso-3166.html\n",
    "        # BeautifulSoup does not parse tags contain \"-\" so\n",
    "        # use find_all to locate the tags with a string search.\n",
    "        tag = soup.org.find_all(\"iso3166-2\")\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        for t in tag:\n",
    "            x = fillna(t)\n",
    "        return x\n",
    "    def get_country(soup):\n",
    "        tag = soup.org.find_all(\"iso3166-1\")\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        for t in tag:\n",
    "            x = fillna(t.find('name'))\n",
    "        return x\n",
    "    def get_countrycode(soup):\n",
    "        tag = soup.org.find_all(\"iso3166-1\")\n",
    "        for t in tag:\n",
    "            x = fillna(t.code2)\n",
    "        return x\n",
    "    def get_organization(soup, info):\n",
    "        # There are 2 tag=name in the tag=org, one for country and one for organization. \n",
    "        # The country is part of iso3166-1 so it can be isolated. Look for organization\n",
    "        # by looking at both tags and selecting the one that is not equal to country.\n",
    "        for t in soup.org.find_all(\"name\"):\n",
    "            if t.string != info[\"country\"]:\n",
    "                x = fillna(t)\n",
    "        return t\n",
    "    def get_timestamp():\n",
    "        return datetime.today()\n",
    "    def get_cidr(soup, info):\n",
    "        tag = soup.net.netblocks\n",
    "        if tag is None:\n",
    "            return None\n",
    "        result = {}\n",
    "        for netblock in tag:\n",
    "            cidr_prefix = fillna(netblock.startaddress)\n",
    "            cidr_length = fillna(netblock.cidrlength)\n",
    "            if (cidr_prefix is None) or (cidr_length is None):\n",
    "                continue\n",
    "            cidr = cidr_prefix + \"/\" + cidr_length\n",
    "            result[cidr] = info\n",
    "        return result if len(result)>0 else None\n",
    "\n",
    "    # Parse html into a hierarchy using BeautifulSoup \n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    # ARIN reports a list of CIDR net_addresses. \n",
    "    # The database will be indexed by ipaddress.net_address.\n",
    "    # A record will be written for each cidr and duplicate the ARIN info\n",
    "    # Obtain the organization name from tag=net instead of the tag=org which\n",
    "    # has more than one tag=name making it harder to isolate.\n",
    "    try:\n",
    "        info = {}\n",
    "\n",
    "        # Obtain info from tag=org\n",
    "\n",
    "        info[\"address\"] = get_streetaddress(soup)\n",
    "        info[\"postalcode\"] = get_postalcode(soup)\n",
    "        info[\"state\"] = get_state(soup)\n",
    "        info[\"country\"] = get_country(soup)\n",
    "        info[\"countrycode\"] = get_countrycode(soup)\n",
    "        info[\"organization\"] = get_organization(soup, info)\n",
    "        info[\"city\"] = get_city(soup)\n",
    "        info[\"handle\"] = get_handle(soup)\n",
    "        info[\"timestamp\"] = get_timestamp()\n",
    "\n",
    "        # Add the risk obtained from scamalytics\n",
    "        info.update(get_risk(ip_string))\n",
    "    \n",
    "        # Parse into dict to return results, item by item\n",
    "        result = get_cidr(soup)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error in parse_arin({ip_string=}\")\n",
    "        print(f\"{html_text=}\")\n",
    "        return None\n",
    "\n",
    "def get_arin(ip_string):\n",
    "    '''Return dict for the net_address that contains this ip_string\n",
    "        {\"cidr\": ?,\n",
    "         {\"organization\": ? ,\n",
    "          \"handle\": ? ,\n",
    "          \"city\": ? ,\n",
    "          \"address\" : ? ,\n",
    "          \"postalcode\": ? ,\n",
    "          \"countrycode\": ? ,\n",
    "          \"state\": ? ,\n",
    "          \"country\": ? ,\n",
    "          \"timestamp\": ?,\n",
    "         }\n",
    "    '''\n",
    "\n",
    "    # Fetch the complete record from arin restful api\n",
    "    # Ref: https://www.arin.net/resources/registry/whois/rws/api/#networks-and-asns\n",
    "    # ip_string ... make request by ip address as a string\n",
    "    # pft ......... get full record\n",
    "    \n",
    "    url = \"http://whois.arin.net/rest/ip/\" + ip_string + \"/pft\"\n",
    "    html_text = \"\"\n",
    "    try:\n",
    "        html_text = requests.get(url).text\n",
    "    except:\n",
    "        return None\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return parse_arin(html_text, ip_string)\n",
    "\n",
    "class Risk():\n",
    "    \n",
    "    def __init__(self, filename, readonly=True):\n",
    "\n",
    "        # Open database. Create as needed.\n",
    "        \n",
    "        self.readonly = readonly\n",
    "        self.open_option = f'{\"r\" if self.readonly else \"w\"}'\n",
    "        self.db_filename = filename\n",
    "        self.hp = pickle.HIGHEST_PROTOCOL\n",
    "         \n",
    "        try:\n",
    "            self.db = dbm.open(self.db_filename, self.open_option)\n",
    "        except:\n",
    "            if self.readonly:\n",
    "                print(f\"{self.db_filename} does not exist but will not be created when class is {readonly=}\")\n",
    "                return None\n",
    "            else:\n",
    "                self.db = dbm.open(self.db_filename, \"c\")\n",
    "                \n",
    "        # Read the data into dictionary:\n",
    "        #   risk[ipaddress.ipv4network] = [organization, country, risk]\n",
    "        #   \n",
    "        \n",
    "        self.risk = SortedDict()\n",
    "        self.risk_count = 0\n",
    "\n",
    "        for key in self.db.keys():\n",
    "            self.risk[pickle.loads(key)] = pickle.loads(self.db[key])\n",
    "\n",
    "        self.risk_count = len(self.risk)\n",
    "        self.db.close()\n",
    "\n",
    "        \n",
    "    def find(self, ip_string):\n",
    "        \"\"\" \n",
    "        risk[cidr] = {organization, handle, city, address, postalcode, countrycode, state, ...}\n",
    "        creating one if needed and adding it to the database.\n",
    "        Return:\n",
    "        - None ........ when Risk.ip is None\n",
    "                        when Risk.ip and not Risk.findarin then Risk.findarin was found \n",
    "                        at ARIN site but could be added to db\n",
    "        - ARIN dict ... Risk.ip and Risk.searchresult (==Risk.ip)\n",
    "                        or Risk.ip and Risk.findarin and Risk.addarin (==Risk.findarin)\n",
    "        \"\"\"\n",
    "\n",
    "        try: \n",
    "            self.ip = ipaddress.ip_address(ip_string)\n",
    "        except:\n",
    "            self.ip = None\n",
    "            print(f\"Could not find IPv4Address for {ip_string}\")\n",
    "            return None\n",
    "        \n",
    "        # Find the address to insert\n",
    "        self.searchresult = None\n",
    "        self.findarin = None\n",
    "        self.addarin = None\n",
    "        \n",
    "        self.searchresult = self.cidr_search(self.ip)\n",
    "        if self.searchresult is None:\n",
    "            self.findarin = get_arin(ip_string)\n",
    "            if self.findarin is None:\n",
    "                debug.prt(f\"No arin results for {ip_string=}\\n\")\n",
    "                return None\n",
    "            self.addarin = self.add(self.findarin)\n",
    "            if self.addarin is None:\n",
    "                debug.prt(f\"ARIN results could not be added for {ip_string=}\\n\")\n",
    "                return None\n",
    "            return self.findarin\n",
    "        else:\n",
    "            return self.searchresult\n",
    "    \n",
    "\n",
    "    def add(self, new_risks):\n",
    "        '''\n",
    "        Add the result of get_arin, a dict with cidr as key \n",
    "        to both the Risk.risk dict and the database.\n",
    "        Return:\n",
    "        None ... No risks to add.\n",
    "                 A risk value could not be pickle'd\n",
    "        True ... Risks added successfully\n",
    "        '''\n",
    "        \n",
    "        if (new_risks is None) or (len(new_risks) == 0) or self.readonly:\n",
    "            return None\n",
    "        \n",
    "        # Store in dictionary first.\n",
    "        # There may be more than one cidr retrieved by get_arin\n",
    "        # Each CIDR has to be type ip_network\n",
    "\n",
    "        for new_cidr, new_risk in new_risks.items():\n",
    "            netblock = ipaddress.ip_network(new_cidr)\n",
    "            self.risk[netblock] = new_risk\n",
    "        \n",
    "        # Store in database next\n",
    "        if not self.readonly:\n",
    "            \n",
    "            # Collect the pickle's of each netblock and risk\n",
    "            additions = []\n",
    "            for new_cidr, new_risk in new_risks.items():\n",
    "                netblock = ipaddress.ip_network(new_cidr)\n",
    "                # key and value have to be pickle'd before storing\n",
    "                try:\n",
    "                    pickled_netblock = pickle.dumps(netblock, protocol=self.hp)\n",
    "                    # This is a hack that allows pickle to work \n",
    "                    new_risk_temp = f\"{new_risk}\"\n",
    "                    pickled_risk     = pickle.dumps(new_risk_temp, protocol=self.hp)\n",
    "                    additions.append([pickled_netblock, pickled_risk])\n",
    "                except BaseException as ex:\n",
    "                    print(ex)\n",
    "                    debug.prt(f\"Pickle error: {new_cidr=}\\n{new_risk=}\\n\")\n",
    "                    return None\n",
    "\n",
    "            # Write into database making sure to close it\n",
    "            with dbm.open(self.db_filename, self.open_option) as self.db:\n",
    "                for addition in additions:\n",
    "                    self.db[addition[0]] = addition[1]\n",
    "\n",
    "        return True\n",
    "    \n",
    "\n",
    "    def len(self):\n",
    "        return self.risk_count\n",
    "\n",
    "\n",
    "    def cidr_search(self, target_ip):\n",
    "        # risk.cidr_search(target_ip) is True when ip's network is in db\n",
    "        # type(target_ip) is ipaddress.IPv4Address\n",
    "        # Updates cidr_search_result property with risk[cidr of target_ip] else None\n",
    "        sz = len(self.risk)\n",
    "        if sz == 0:\n",
    "            self.bisearch_result = None\n",
    "            return False\n",
    "        s = 0\n",
    "        e = sz\n",
    "        while s > e:\n",
    "            m = (s + e)//2\n",
    "            cidr = self.risk.peekitem(m)[0]\n",
    "            if target_ip in cidr:\n",
    "                self.cidr_search_result = self.risk[cidr]\n",
    "                return True\n",
    "            if target_ip > cidr:\n",
    "                s = m + 1\n",
    "            else:\n",
    "                e = m - 1\n",
    "        self.cidr_search_result = None\n",
    "        return False\n",
    "\n",
    "\n",
    "# Routine to read a clean set ip addresses from the sample data\n",
    "# and icorporate them into the risk database\n",
    "\n",
    "db_filename = \"mywhois\"\n",
    "sample_filename = \"clean_test_data.csv\"\n",
    "\n",
    "# Open the database and load the current data\n",
    "risk = Risk(db_filename, readonly=False)\n",
    "\n",
    "# Read the clean set of sample data set\n",
    "clean_ip = pd.read_csv(sample_filename)\n",
    "                       \n",
    "# range over the unique ip addresses\n",
    "new = 0\n",
    "old = 0\n",
    "for n, ip in enumerate(clean_ip.ip.drop_duplicates()[:10]):\n",
    "    before = risk.len()\n",
    "    risk.find(ip)\n",
    "    after  = risk.len()\n",
    "    if before == after:\n",
    "        old += 1\n",
    "    else:\n",
    "        new += after - before\n",
    "        \n",
    "print(f\"{n=} {new=} {old=} {risk.len()=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_arin(ip_string):\n",
    "    url       = \"http://whois.arin.net/rest/ip/\" + ip_string + \"/pft\"\n",
    "    html_text = \"\"\n",
    "    try:\n",
    "        html_text = requests.get(url).text\n",
    "    except:\n",
    "        return None\n",
    "    # Parse html into a hierarchy using BeautifulSoup \n",
    "#     soup = BeautifulSoup(html_text, 'lxml')\n",
    "    soup = BeautifulSoup(html_text, 'xml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = api_arin(\"24.228.215.103\")\n",
    "print(f\"{len(soup)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.netblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routine to read a clean set ip addresses from the sample data\n",
    "# and icorporate them into the resk database\n",
    "\n",
    "db_filename = \"mywhois\"\n",
    "sample_filename = \"clean_test_data.csv\"\n",
    "\n",
    "# Open the database and load the current data\n",
    "risk = Risk(db_filename, readonly=False)\n",
    "\n",
    "# Read the clean set of sample data set\n",
    "clean_ip = pd.read_csv(sample_filename)\n",
    "                       \n",
    "# range over the unique ip addresses\n",
    "new = 0\n",
    "old = 0\n",
    "for n, ip in enumerate(clean_ip.ip.drop_duplicates()[2:3]):\n",
    "    before = risk.len()\n",
    "    risk.find(ip)\n",
    "    after  = risk.len()\n",
    "    if before == after:\n",
    "        old += 1\n",
    "    else:\n",
    "        new += 1\n",
    "print(f\"{n=} {new=} {old=} {risk.len()=}\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk=Risk(\"mywhois\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142.255.122.114\n",
      "172.58.230.193\n",
      "72.68.212.63\n",
      "172.100.125.174\n",
      "24.228.215.103\n",
      "68.199.195.147\n",
      "108.29.95.66\n",
      "32.208.115.88\n",
      "24.189.68.18\n",
      "172.58.235.43\n"
     ]
    }
   ],
   "source": [
    "for ip in clean_ip.ip.drop_duplicates()[:10]:\n",
    "    print(ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work={'organization': 'MCI Communications Services, Inc. d/b/a Verizon Business', 'handle': 'MCICS', 'asn': '', 'city': 'Ashburn', 'address': ['22001 Loudoun County Pkwy'], 'postalcode': '20147', 'state': 'VA', 'country': 'United States', 'ip': '72.68.212.63', 'score': '21', 'risk': 'medium', 'risk_comment': 'IP address 72.68.212.63 is operated by Verizon Communications whose web traffic we consider to present a potentially medium fraud risk. This IP address is owned by MCI Communications Services, Inc. d/b/a Verizon Business whose web traffic we also consider to present a potentially medium fraud risk. In both cases, non-web traffic may present a different risk or no risk at all. Scamalytics see low levels of traffic from Verizon Communications across our global network, little of which we suspect to be potentially fraudulent. We have no visibility into the web traffic directly from 72.68.212.63, and therefore apply a risk score of 21/100 based on the overall risk from Verizon Communicationsâ€™s IP addresses where we do have visibility.'}\n",
    "pickle.dumps(f\"{work}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in risk.risk:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2754/474661594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# s.org\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iso3166-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mcountry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# t=requests.get(\"http://whois.arin.net/rest/ip/\" + ip_string + \"/pft\").text\n",
    "\n",
    "# s = BeautifulSoup(t)\n",
    "\n",
    "# s.org\n",
    "\n",
    "# for x in s.org.find_all(\"iso3166-1\"):\n",
    "#     country = x.find('name').string\n",
    "# print(country)\n",
    "\n",
    "# for x in s.org.find_all(\"name\"):\n",
    "#     if x.string != country:x\n",
    "#         organization = x.string\n",
    "\n",
    "\n",
    "# print(organization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arin(html_text, ip_string):\n",
    "    # Values that are not found are set to np.NaN\n",
    "    \n",
    "    fillna = lambda x: np.nan if x is None else x if isinstance(x, str) else x.string\n",
    "    \n",
    "    def get_streetaddress(soup):\n",
    "        # More than one address line may be recorded\n",
    "        tag = soup.org.streetaddress\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        address = []\n",
    "        for line in tag:\n",
    "            address.append(line.string)\n",
    "        return address\n",
    "    def get_postalcode(soup):\n",
    "        return fillna(soup.org.postalcode)\n",
    "    def get_city(soup):\n",
    "        return fillna(soup.org.city)\n",
    "    def get_handle(soup):\n",
    "        return fillna(soup.org.handle)\n",
    "    def get_state(soup):\n",
    "        # The iso3166 tags are the international country codes\n",
    "        # Ref: https://www.iso.org/glossary-for-iso-3166.html\n",
    "        # BeautifulSoup does not parse tags contain \"-\" so\n",
    "        # use find_all to locate the tags with a string search.\n",
    "        tag = soup.org.find_all(\"iso3166-2\")\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        for t in tag:\n",
    "            x = fillna(t)\n",
    "        return x\n",
    "    def get_country(soup):\n",
    "        tag = soup.org.find_all(\"iso3166-1\")\n",
    "        if tag is None:\n",
    "            return np.nan\n",
    "        for t in tag:\n",
    "            x = fillna(t.find('name'))\n",
    "        return x\n",
    "    def get_countrycode(soup):\n",
    "        tag = soup.org.find_all(\"iso3166-1\")\n",
    "        for t in tag:\n",
    "            x = fillna(t.code2)\n",
    "        return x\n",
    "    def get_organization(soup, info):\n",
    "        # There are 2 tag=name in the tag=org, one for country and one for organization. \n",
    "        # The country is part of iso3166-1 so it can be isolated. Look for organization\n",
    "        # by looking at both tags and selecting the one that is not equal to country.\n",
    "        for t in soup.org.find_all(\"name\"):\n",
    "            if t.string != info[\"country\"]:\n",
    "                x = fillna(t)\n",
    "        return t\n",
    "    \n",
    "    # Parse into dict to return results, item by item\n",
    "    result = {}\n",
    "\n",
    "    # Parse html into a hierarchy using BeautifulSoup \n",
    "    soup = BeautifulSoup(html_text, 'lxml')\n",
    "\n",
    "    # ARIN reports a list of CIDR net_addresses. \n",
    "    # The database will be indexed by ipaddress.net_address.\n",
    "    # A record will be written for each cidr and duplicate the ARIN info\n",
    "    # Obtain the organization name from tag=net instead of the tag=org which\n",
    "    # has more than one tag=name making it harder to isolate.\n",
    "    try:\n",
    "        info = {}\n",
    "\n",
    "        # Obtain info from tag=org\n",
    "\n",
    "        info[\"address\"] = get_streetaddress(soup)\n",
    "        info[\"postalcode\"] = get_postalcode(soup)\n",
    "        info[\"state\"] = get_state(soup)\n",
    "        info[\"country\"] = get_country(soup)\n",
    "        info[\"countrycode\"] = get_countrycode(soup)\n",
    "        info[\"organization\"] = get_organization(soup, info)\n",
    "        info[\"city\"] = get_city(soup)\n",
    "        info[\"handle\"] = get_handle(soup)\n",
    "\n",
    "        # Add the risk obtained from scamalytics\n",
    "#         info.update(get_risk(ip_string))\n",
    "\n",
    "        # The netblocks scope contains a list of netblock sections\n",
    "        for netblock in soup.net.netblocks:\n",
    "            cidr = netblock.startaddress.string + \"/\" + netblock.cidrlength.string      \n",
    "            result[cidr] = info\n",
    "        return result\n",
    "    \n",
    "    except:\n",
    "        print(f\"Error in parse_arin({ip_string=}\")\n",
    "        print(f\"{html_text=}\")\n",
    "        return None\n",
    "\n",
    "def xget_arin(ip_string):\n",
    "    '''Return dict for the net_address that contains this ip_string\n",
    "        {\"cidr\": ?,\n",
    "         {\"organization\": ? ,\n",
    "          \"handle\": ? ,\n",
    "          \"city\": ? ,\n",
    "          \"address\" : ? ,\n",
    "          \"postalcode\": ? ,\n",
    "          \"countrycode\": ? ,\n",
    "          \"state\": ? ,\n",
    "          \"country\": ? ,\n",
    "         }\n",
    "    '''\n",
    "\n",
    "    # Fetch the complete record from arin restful api\n",
    "    # Ref: https://www.arin.net/resources/registry/whois/rws/api/#networks-and-asns\n",
    "    # ip_string ... make request by ip address as a string\n",
    "    # pft ......... get full record\n",
    "    \n",
    "    url = \"http://whois.arin.net/rest/ip/\" + ip_string + \"/pft\"\n",
    "    html_text = \"\"\n",
    "    try:\n",
    "        html_text = requests.get(url).text\n",
    "    except:\n",
    "        return None\n",
    "#     import pdb; pdb.set_trace()\n",
    "    return parse_arin(html_text, ip_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'72.65.128.0/17': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                    'city': 'Ashburn',\n",
      "                    'country': 'United States',\n",
      "                    'countrycode': 'US',\n",
      "                    'handle': 'MCICS',\n",
      "                    'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                    'postalcode': '20147',\n",
      "                    'state': 'VA'},\n",
      " '72.66.0.0/15': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                  'city': 'Ashburn',\n",
      "                  'country': 'United States',\n",
      "                  'countrycode': 'US',\n",
      "                  'handle': 'MCICS',\n",
      "                  'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                  'postalcode': '20147',\n",
      "                  'state': 'VA'},\n",
      " '72.68.0.0/15': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                  'city': 'Ashburn',\n",
      "                  'country': 'United States',\n",
      "                  'countrycode': 'US',\n",
      "                  'handle': 'MCICS',\n",
      "                  'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                  'postalcode': '20147',\n",
      "                  'state': 'VA'},\n",
      " '72.70.0.0/16': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                  'city': 'Ashburn',\n",
      "                  'country': 'United States',\n",
      "                  'countrycode': 'US',\n",
      "                  'handle': 'MCICS',\n",
      "                  'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                  'postalcode': '20147',\n",
      "                  'state': 'VA'},\n",
      " '72.71.0.0/17': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                  'city': 'Ashburn',\n",
      "                  'country': 'United States',\n",
      "                  'countrycode': 'US',\n",
      "                  'handle': 'MCICS',\n",
      "                  'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                  'postalcode': '20147',\n",
      "                  'state': 'VA'},\n",
      " '72.71.128.0/18': {'address': ['22001 Loudoun County Pkwy'],\n",
      "                    'city': 'Ashburn',\n",
      "                    'country': 'United States',\n",
      "                    'countrycode': 'US',\n",
      "                    'handle': 'MCICS',\n",
      "                    'organization': <name>MCI Communications Services, Inc. d/b/a Verizon Business</name>,\n",
      "                    'postalcode': '20147',\n",
      "                    'state': 'VA'}}\n"
     ]
    }
   ],
   "source": [
    "ip_string = \"72.68.212.63\"\n",
    "pp.pprint(xget_arin(ip_string))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'256.0.0.0' does not appear to be an IPv4 or IPv6 address",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2754/3525169257.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mipaddress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mip_address\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"256.0.0.0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/dmv_test/lib/python3.9/ipaddress.py\u001b[0m in \u001b[0;36mip_address\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     raise ValueError('%r does not appear to be an IPv4 or IPv6 address' %\n\u001b[0m\u001b[1;32m     54\u001b[0m                      address)\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: '256.0.0.0' does not appear to be an IPv4 or IPv6 address"
     ]
    }
   ],
   "source": [
    "ip = ipaddress.ip_address(\"256.0.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dmv_test]",
   "language": "python",
   "name": "conda-env-dmv_test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
